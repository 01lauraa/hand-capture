<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Hand Image Capture with Detection</title>
  <style>
    html, body {
      margin: 0;
      padding: 0;
      height: 100%;
      width: 100%;
      background: #000;
      overflow: hidden;
      font-family: Arial, sans-serif;
      color: white;
    }

    header {
      background: #00356b;
      color: white;
      padding: 10px 0;
      font-size: 18px;
      text-align: center;
    }

    #camera-container {
      position: relative;
      width: 100%;
      max-width: 800px;
      height: 88vh;
      margin: 0 auto;
      border-radius: 10px;
      overflow: hidden;
      background: #000;
    }

    video, #photo {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
    }

    #hand-overlay {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      pointer-events: none;
      opacity: 0.6;
      object-fit: contain;
    }

    #buttons {
      position: absolute;
      bottom: 70px;
      width: 100%;
      text-align: center;
      z-index: 5;
    }

    button {
      margin: 0 10px;
      padding: 12px 26px;
      font-size: 18px;
      border: none;
      background: rgba(0,115,230,0.9);
      color: white;
      border-radius: 8px;
      cursor: pointer;
    }

    button:hover {
      background: rgba(0,91,181,0.9);
    }

    #statusMsg {
      position: absolute;
      bottom: 35px;
      width: 100%;
      text-align: center;
      font-size: 16px;
      color: #fff;
    }

    h3 {
      margin: 12px 0;
      font-weight: normal;
      color: #ddd;
    }
  </style>

  <!-- ONNX Runtime -->
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.17.0/dist/ort.min.js"></script>
</head>

<body>
  <header>Hand Image Capture</header>
  <h3>Place your hand inside the outline and take a photo</h3>

  <div id="camera-container">
    <video id="video" autoplay playsinline muted></video>
    <img src="assets/hand_outline_clean1.png" id="hand-overlay" alt="Overlay guide">
    <canvas id="canvas" style="display:none;"></canvas>
    <img id="photo" alt="Captured photo preview">
  </div>

  <div id="buttons">
    <button id="captureBtn">Take Photo</button>
    <button id="retakeBtn" style="display:none;">Retake</button>
    <button id="selectBtn" style="display:none;">Select</button>
    <button id="downloadBtn" style="display:none;">Download</button>
  </div>

  <p id="statusMsg"></p>

  <script>
    // DOM elements
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const photo = document.getElementById('photo');
    const overlay = document.getElementById('hand-overlay');
    const captureBtn = document.getElementById('captureBtn');
    const retakeBtn = document.getElementById('retakeBtn');
    const selectBtn = document.getElementById('selectBtn');
    const downloadBtn = document.getElementById('downloadBtn');
    const statusMsg = document.getElementById('statusMsg');
    const container = document.getElementById('camera-container');

    // YOLO model
    const modelPath = "assets/model/last.onnx";
    let session = null;

    async function loadModel() {
      statusMsg.textContent = "Loading YOLO model...";
      try {
        session = await ort.InferenceSession.create(modelPath);
        statusMsg.textContent = "Model loaded ✅";
      } catch (err) {
        statusMsg.textContent = "Model load failed: " + err;
      }
    }
    loadModel();

    // Camera setup
    navigator.mediaDevices.getUserMedia({
      video: { facingMode: "environment", width: { ideal: 1920 }, height: { ideal: 1080 } }
    })
    .then(stream => {
      video.srcObject = stream;
      return video.play();
    })
    .then(() => {
      const resizeOverlay = () => {
        overlay.style.width = container.clientWidth + "px";
        overlay.style.height = container.clientHeight + "px";
      };
      resizeOverlay();
      window.addEventListener('resize', resizeOverlay);
    })
    .catch(err => alert("Camera access denied: " + err));

    // Take photo
    captureBtn.addEventListener('click', () => {
      const ctx = canvas.getContext('2d');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      photo.src = canvas.toDataURL('image/png');
      video.style.display = 'none';
      overlay.style.display = 'none';
      photo.style.display = 'block';
      captureBtn.style.display = 'none';
      retakeBtn.style.display = 'inline-block';
      selectBtn.style.display = 'inline-block';
      statusMsg.textContent = "Photo captured. Click Select to run detection.";
    });

    // Retake
    retakeBtn.addEventListener('click', () => {
      photo.style.display = 'none';
      video.style.display = 'block';
      overlay.style.display = 'block';
      captureBtn.style.display = 'inline-block';
      retakeBtn.style.display = 'none';
      selectBtn.style.display = 'none';
      downloadBtn.style.display = 'none';
      statusMsg.textContent = "";
    });

    // Select (Run YOLO)
    selectBtn.addEventListener('click', async () => {
      if (!session) {
        statusMsg.textContent = "Model not loaded yet.";
        return;
      }
      statusMsg.textContent = "Running detection...";
      await runDetection(photo);
    });

    // Download
    downloadBtn.addEventListener('click', () => {
      const link = document.createElement('a');
      link.href = photo.src;
      link.download = 'hand_detected.png';
      link.click();
    });

    // Run YOLO detection
    async function runDetection(img) {
      const tensor = await imageToTensor(img, 640);
      const output = await session.run({ images: tensor });
      const key = Object.keys(output)[0];
      const boxes = decodeYOLO(output[key].data, 640, img.width, img.height, 0.25);
      const filtered = nms(boxes, 0.45);
      drawBoxes(img, filtered);
    }

    // Convert image to tensor
    async function imageToTensor(img, size) {
      const canvasTmp = document.createElement('canvas');
      canvasTmp.width = size;
      canvasTmp.height = size;
      const ctx = canvasTmp.getContext('2d');
      ctx.drawImage(img, 0, 0, size, size);
      const { data } = ctx.getImageData(0, 0, size, size);
      const floatData = new Float32Array(size * size * 3);
      for (let i = 0; i < size * size; i++) {
        floatData[i] = data[i * 4 + 0] / 255;
        floatData[i + size * size] = data[i * 4 + 1] / 255;
        floatData[i + 2 * size * size] = data[i * 4 + 2] / 255;
      }
      return new ort.Tensor('float32', floatData, [1, 3, size, size]);
    }

    // Decode YOLO output
    function decodeYOLO(arr, modelSize, imgW, imgH, confThr) {
      const boxes = [];
      const nPreds = arr.length / 5;

      for (let i = 0; i < nPreds; i++) {
        const off = i * 5;
        const conf = arr[off + 4];
        if (conf > confThr) {
          const cx = arr[off + 0];
          const cy = arr[off + 1];
          const w = arr[off + 2];
          const h = arr[off + 3];

          const x1 = cx - w / 2;
          const y1 = cy - h / 2;
          const x2 = cx + w / 2;
          const y2 = cy + h / 2;

          boxes.push({ x1, y1, x2, y2, conf });
        }
      }
      return boxes;
    }

    // --- Non-Max Suppression (YOLO-style) ---
    function nms(boxes, iouThresh = 0.45) {
      const keep = [];
      boxes.sort((a, b) => b.conf - a.conf);
      while (boxes.length) {
        const chosen = boxes.shift();
        keep.push(chosen);
        boxes = boxes.filter(b => iou(b, chosen) < iouThresh);
      }
      return keep;
    }

    function iou(a, b) {
      const interX1 = Math.max(a.x1, b.x1);
      const interY1 = Math.max(a.y1, b.y1);
      const interX2 = Math.min(a.x2, b.x2);
      const interY2 = Math.min(a.y2, b.y2);
      const interArea = Math.max(0, interX2 - interX1) * Math.max(0, interY2 - interY1);
      const areaA = (a.x2 - a.x1) * (a.y2 - a.y1);
      const areaB = (b.x2 - b.x1) * (b.y2 - b.y1);
      return interArea / (areaA + areaB - interArea);
    }

    // Draw boxes
    function drawBoxes(img, boxes) {
      boxes.sort((a, b) => b.conf - a.conf);
      const finalBoxes = boxes.length > 4 ? boxes.slice(0, 4) : boxes;
      const canvasDet = document.createElement('canvas');
      canvasDet.width = img.width;
      canvasDet.height = img.height;
      const ctx = canvasDet.getContext('2d');
      ctx.drawImage(img, 0, 0, img.width, img.height);
      ctx.lineWidth = 3;
      ctx.strokeStyle = 'lime';
      ctx.font = '20px Arial';
      ctx.fillStyle = 'lime';
      finalBoxes.forEach(b => {
        ctx.strokeRect(b.x1, b.y1, b.x2 - b.x1, b.y2 - b.y1);
        ctx.fillText('Nail ' + b.conf.toFixed(2), b.x1 + 4, b.y1 + 22);
      });
      photo.src = canvasDet.toDataURL('image/png');
      statusMsg.textContent = `Detected ${finalBoxes.length} nail(s) ✅`;
      selectBtn.style.display = 'none';
      downloadBtn.style.display = 'inline-block';
    }
  </script>
</body>
</html>
